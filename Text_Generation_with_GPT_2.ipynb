{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v50sG5eBj4FU",
    "outputId": "416073f5-4bf6-4cc0-8c13-f1005d1df5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400,
     "referenced_widgets": [
      "9932d364864d4d2b84a98ea1db9de8c7",
      "e9c28ef189e74d78aa1661cbf686b900",
      "b30a5122904c420e8ac594db733ffecb",
      "2ad87ea8fc394c35a24f7dae4ed37372",
      "20879cc77ec34aa5a9ce67f65218c6ed",
      "6d39104789e4498ebda0db6bd4279044",
      "c15e4db5367c480ea6bea004fbcdb3b6",
      "919d648f279948c5844dc10efd4fbf9c",
      "68f59d04f79a4b08806e704a2ea0eec6",
      "4b6a1e9596bc4f72900ffb44d60ea2f5",
      "38b1d9ef5def49e38d0b1db05a388703",
      "f2e803de658b4a648ae88f6d1979d2ce",
      "cec32f15c35b4a5593ef6e14f8e1b4cd",
      "601b4c986c644d1583aa6212e333c693",
      "4ba57bdaab5d4c6c99fe85cac7b42b1f",
      "d98d280f0aa6451db59a0929c45e80bc",
      "bf1d026796864f83837506c50be91a69",
      "2c6a7d50037a47a5906e93e15006bbb5",
      "8804504daf8843e9b58a6dd053baec44",
      "023e22fd0cf6496db24398d4b61d354b",
      "50ad0679a2e14e63a5b9b627edc89dcd",
      "d6555e595d1b42d69ebdb57e4437f29a",
      "2f86667b6846409a9c32455eea2a3409",
      "921ce776b499447d90453b3e04f2f9df",
      "098a64e151f7494585768c6d3c73595d",
      "69cc66eb26124b2da1ebee121dc7dcae",
      "652e00eeb57546d8bda7b12c197b0ae2",
      "95e7fb43ff484e2ab232c54ec7d3482d",
      "c69ee22cc57845edb2490c212c5b119f",
      "421481f2d9ef47d9a460a7a0c82ace42",
      "6b169291558f4af6b18482bf88a0841e",
      "9ed7a23058b3412e89b253943941d873",
      "74050d624aaf45bdbc2625e170464237",
      "b82eb0ec25394d67b2ead612400ba038",
      "6ad0b6af0d5d428bb7f0e1b00b8867fe",
      "14ba6bdb862f45cb8e27e95f3b371bfa",
      "3fd82cf3622d42e6a1529e07e5046776",
      "0875bc4f97cb45f1bd68dab949c67c86",
      "ff167de31f20423a8b06164dd2143c83",
      "144b5e58872b47aa84c41b1b3ae68de2",
      "a776c5e42c3147d89e9ae755f11f0c4b",
      "9133291fad944b61a2b2dabf27384c88",
      "a951f07764854df99a13dc59d9bd3e86",
      "4f48363f916a46509a34ad7986e6d16d",
      "c8740304fac04bfe8cb3ad259e85628b",
      "a11f4ddd84bf49d392572384b7563ba7",
      "a118a968fa1c4b6892bf71f938a97218",
      "545072a513fe4bd2858dd4a699d92a07",
      "85331c5c57dc40cda5928b841347378b",
      "26e0b6b0ca514de88c3a92a7bb35b9f9",
      "e60e5e60213c4fb5b049b04edb5eb335",
      "daa02e98843e44fba00c483c33f0bf57",
      "844614aa30b64231a4b018665e02efd6",
      "7192ae327753496ab95731f634b60837",
      "c6cf2683030f4df599bcc0051e27e720",
      "7cbcc55a5da1402a9981b881fa87bdd6",
      "e4e63aba6d994c4d8a5005e0d4ef5c34",
      "1f5fcc0ce5da45e5a8cfbca9ce9693f3",
      "debf40dee0564fa382ae316be3a404c0",
      "a45ae8309db84ff49f890d852f51caee",
      "abff9e32b5a649f3b909d6b2c899517b",
      "2c953db9371545d7b3b6659b9da4e408",
      "c9ec4b2f41fe482daec1c091a3d690ce",
      "c6f56390f82d4839b9b2a45d5d8899e5",
      "ee2e448343fc4456a202a487714898eb",
      "ad9e15984da54fc2ac711924f78d74cb",
      "1b1b849bd94848b39e000d8cf5fbc5a3",
      "4e48c4bea3674478b5c42ff7edc79c5a",
      "3baf9df230594b83b960aea4aef999e2",
      "c017640c34674dc994b99ff32c1fb25b",
      "85b2dda6a13e41bcbd20bfc2e1f95477",
      "6ffaf0f3ecb84a74844b4cfd3833217b",
      "7ec1b1ce6a244d0ba59f645ee68a24c6",
      "c79a03ea83de4e68aba310039a4b76c0",
      "156c6796b568432eb454daf873ea03fb",
      "544ff259271d4b079e5d4b791723df80",
      "7dd2a6a9fb564730a844ef7b36e7f96f"
     ]
    },
    "id": "_7SPMyNZkWhb",
    "outputId": "b81bc941-f228-45bb-9a78-ed42ffa3d1e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9932d364864d4d2b84a98ea1db9de8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e803de658b4a648ae88f6d1979d2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f86667b6846409a9c32455eea2a3409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82eb0ec25394d67b2ead612400ba038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8740304fac04bfe8cb3ad259e85628b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbcc55a5da1402a9981b881fa87bdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1b849bd94848b39e000d8cf5fbc5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Using device: GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
    "print(\"Model loaded. Using device:\", \"GPU\" if device == 0 else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "50ddc13a88c4499bbe5ab64802268afa",
      "f9976bbdfc084656bf49010e38eaac2c",
      "1f7da9685af4481ab4f46e4a5b52b68e",
      "789b1b3536d942dc911ca6fcf1a479f1",
      "5eba1e6577df4fd094f9fce8214cc770",
      "91521f9e9ba948d4a1984e20bb589c22",
      "eaebd1e7bbe049068c66e826a6f032b5",
      "f041300091b645df8abe73f2be54d132",
      "2d13e43091004d9ba55f97abe5e6a76b",
      "04b9e96b648c44fda14608352c9834eb",
      "c5ffc98a86f346d2bf3a7b3a260589f6",
      "6e47ccb91ddb400ab729f89855b2cee4",
      "475a6e9da8d8424b889c90a6d09f74b9",
      "5cb22acb290240aebe959375f6f23d10",
      "a91a3ff1acc3447a8471cdd170f0b058",
      "51e1e3a225b14b02a5ae47430629ea3d",
      "7ccefb901fe34f2b813439e9b82a9e72",
      "d026639fbe3843bdbb42a474587a8ee5",
      "8a94e020ea1547d9a3a7c934061b9c8d",
      "719bd1d4fd3e4e24a95ea0a3a4e64bf0",
      "e0897e14276b491fb40022fc185e50c0",
      "01585c9b95564dbc8ec628e2f74a46fe",
      "1aa379c587b341479a68219f77e77142",
      "851f4abf03184822ac18bbe87194ce9e",
      "0dd39ef6329a45aea6a920065e93e715",
      "315402d870494175b72707a1d1967441",
      "631e288be79d472b96743735b66d8405",
      "14e993babfe84ca59f9e8e87eb22b9c8",
      "7578d3fd2a4a4ef9a65341a6fd2fe958",
      "aa17e6918fdc4d918cbe17fe1112325e",
      "9843d0023cdc44d18a47f0436c290b16",
      "ef0b09c4b4f44003a07d1fca1350027d",
      "77e66d96766c4a2f9ac6e95efff02730",
      "0de8a9d8dc5643278335e65cd79aceb0",
      "3170173f0bf544e39a429f677a2ce3ca",
      "44de24ffabb641c2ab7b05d1814f5db1",
      "c6e84a8cfe234f58acc738fd1f74ea4c",
      "e1e33d8b097b43baa8489b422672fd2b",
      "d4247d184a82475daa7fe0cbed96a923",
      "0d760c9d192f4c96ac457c0ba4fd9a40",
      "20aadb2b7e5e4e97ad5c666b71514646",
      "d6e26c29ab5c4f49a88a6f0297d788b0",
      "52adafe48b954d98b92eebf93765fe36",
      "a4c699013b844529b085ab4105d570ef",
      "a1e6fcaeb5f14460b759591473c6ec96",
      "dd7e7189dfde4a5a99ea1a74a9d77782",
      "08123e3daa9f4c6fb2c3cea6b54e1348",
      "82a325632c054563bcff3119283d8454",
      "ae8b8f29d2f94c3980210c31a7d43134",
      "6f965755fe3f4abab26901ee46d39b54",
      "253fd74a7c374cb78f03e64c7f53b106",
      "bd6ea66abca748998544eedcd4ee111b",
      "3b97bdd3706a448294e1727e607e1083",
      "4c7dfc7af9c241fe97d72baec85541fe",
      "6a9e5f6d3edd4c88bea51119a38f6e44",
      "de16697c17bb400f9ac2ba5878580504",
      "45abf96976fb4da687d1aa38441d6ead",
      "51844003f5a1483aac1019d3575ee11a",
      "60cd6c21ee0640749ba01d06953b59cc",
      "88c357bd04ab489783f51c504888f825",
      "1bfd53b3fdd04dfd8ed9914b06210391",
      "23b36a3dcad54091ba21047eb44a03dc",
      "dc82881e888c411b9dfbff061100768d",
      "6f4e9dfbe78e4c33bff5af79d2833dda",
      "a53a8895f563462b97ab386ba9880b94",
      "5db11becd3614ea5929b4fa79e4104d3",
      "a6f889ab2a204f9f9334bb1073079ab7",
      "33db4c43c8394b1da6e6b993c2011ddc",
      "1aff167f73704ad6b43cc1d070b575b0",
      "1170f1cf1b79451ba329df887e6f8b75",
      "ae5e875ed50747369d6c6f4d5f14f389",
      "b4d1db88ce6c4d7391cdb2aac61058a9",
      "ae189257594c4bff9084e9881eb0f186",
      "76eb1d8007f149358817bb806e095015",
      "8437c259deb04fe290ad8b760f39aa7b",
      "28647c7b4a2c4cd3baddfc9d239d7dcc",
      "5d956c2f2d974dcfb8f78fb55498af5f",
      "54d4dcd1008b4eac92d5cddeab555054",
      "35b6cdc4d0d04d9fa5bdccf110ef9b3b",
      "9ade619df09f4fcc8f2a9c06dbeac434",
      "9704ff6d537e4366b976eb8a0e521ae7",
      "cec2cf65f08047469739d943a32b7ef2",
      "fa4bf36342d84853812a2767ac22c792",
      "984daa83acb347fa8b831fed3cee50bd",
      "a19319aa629343c883decbc57baabc70",
      "bf3da0896e674793b1528058695c7c71",
      "e2925576c19a4cb7aad74c1ad422ce17",
      "5d38547f25c842679dd8fff3658daab2",
      "4e71a5887bf9449ba85099572624bc07",
      "aa677f7752c64ed98a66f96d3f821a23",
      "fc4b0b9719e74a1fb50c1e5535152bb6",
      "db9d99f3642a46c69eb3996a938ac416",
      "87e40d1c194641b894559ffca1aba593",
      "30cd9a72e4b742689bc050572ba91e7e",
      "75257d99e02948b38223011074cbc331",
      "191afa0ba3fa4bfc922021bf5d6cabbb",
      "936262ddaa8344619dbffb6e55b53314",
      "e9abf36b5d654a94b379548138d54cfc",
      "b8035553d4e7430b9b5cf63d002c17fd",
      "e692068051de4579a2aad5c2b072e675",
      "22627303452f4bdd8631acf8516eae8c",
      "9f133cc1dc8143b0af1ce555d8465feb",
      "a68afebbbd98404cb983a7e1d2ca4b9a",
      "21df5d76e6fc49b8811b8ef48d90403d",
      "b809f17ce22746daada8a6b82adac20e",
      "04c879b3de0e4c0b81b10c008b996e68",
      "e2c69c13a88e4079823a386acfc969e2",
      "eee91128e7f24a5cb72c4b88f5c32380",
      "8de2bb4eee6442e392c6358dba541068",
      "c35ab55897e6435292daa3b89e6d9ab2",
      "4d6a100a69d549359f134465c050c2fe",
      "f8bddf4fd88d4307b4eda6c013149e51",
      "d93398f4941443aeaf1814e581c2443f",
      "a82f2f610d334eaeba9249aab173e490",
      "f2bbbc00c24c404291a9c7d13b8c332d"
     ]
    },
    "id": "AmSVMyeakXn3",
    "outputId": "9b2e6573-3bf2-43ca-8bcc-5a20bf9eefc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.3/1.6 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hLoading GPT-2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ddc13a88c4499bbe5ab64802268afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e47ccb91ddb400ab729f89855b2cee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa379c587b341479a68219f77e77142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de8a9d8dc5643278335e65cd79aceb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e6fcaeb5f14460b759591473c6ec96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de16697c17bb400f9ac2ba5878580504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f889ab2a204f9f9334bb1073079ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model ready!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>✨ Text Generation with GPT-2</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d4dcd1008b4eac92d5cddeab555054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Prompt:', layout=Layout(height='120px', width='75%'), placeholder='Type a shor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9704ff6d537e4366b976eb8a0e521ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Samples:', options=('A futuristic city run by robots', 'An alien studying…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e71a5887bf9449ba85099572624bc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Style:', options=('Normal', 'Funny', 'Poetic', 'Sci-fi', 'Romantic'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68afebbbd98404cb983a7e1d2ca4b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=100, description='Max length:', max=400, min=20, step=10), FloatSlider(value=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82f2f610d334eaeba9249aab173e490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "!pip install transformers ipywidgets --quiet\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from transformers import pipeline\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Loading GPT-2 model...\")\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\", device=-1)\n",
    "print(\"✅ Model ready!\")\n",
    "\n",
    "prompt_area = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Type a short prompt... e.g. A futuristic city run by robots\",\n",
    "    description=\"Prompt:\",\n",
    "    layout=widgets.Layout(width='75%', height='120px')\n",
    ")\n",
    "\n",
    "style_dd = widgets.Dropdown(\n",
    "    options=[\"Normal\", \"Funny\", \"Poetic\", \"Sci-fi\", \"Romantic\"],\n",
    "    value=\"Normal\",\n",
    "    description=\"Style:\"\n",
    ")\n",
    "\n",
    "sample_list = [\n",
    "    \"A futuristic city run by robots\",\n",
    "    \"An alien studying human behaviour\",\n",
    "    \"An AI storyteller exploring emotions\"\n",
    "]\n",
    "sample_dd = widgets.Dropdown(options=sample_list, description=\"Samples:\")\n",
    "\n",
    "insert_sample_btn = widgets.Button(description=\"Insert sample\", button_style='primary')\n",
    "generate_btn = widgets.Button(description=\"Generate\", button_style='success')\n",
    "save_btn = widgets.Button(description=\"Save as .txt\", button_style='info')\n",
    "download_btn = widgets.Button(description=\"Download\", button_style='warning')\n",
    "\n",
    "\n",
    "maxlen_slider = widgets.IntSlider(value=100, min=20, max=400, step=10, description='Max length:')\n",
    "temp_slider = widgets.FloatSlider(value=0.8, min=0.1, max=1.5, step=0.1, description='Temp:')\n",
    "top_p_slider = widgets.FloatSlider(value=0.9, min=0.1, max=1.0, step=0.05, description='Top-p:')\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def insert_sample(_):\n",
    "    prompt_area.value = sample_dd.value\n",
    "\n",
    "def run_generation(_):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        raw = prompt_area.value.strip()\n",
    "        if not raw:\n",
    "            display(HTML(\"<p style='color:red'><b>Please enter a prompt first.</b></p>\"))\n",
    "            return\n",
    "\n",
    "        style = style_dd.value\n",
    "        if style != \"Normal\":\n",
    "            full_prompt = f\"Write a {style.lower()} version of the following: {raw}\"\n",
    "        else:\n",
    "            full_prompt = raw\n",
    "\n",
    "        max_len = maxlen_slider.value\n",
    "        temperature = temp_slider.value\n",
    "        top_p = top_p_slider.value\n",
    "\n",
    "        generated = generator(\n",
    "            full_prompt,\n",
    "            max_length=max_len,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            num_return_sequences=1\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "        output_area.generated_result = generated\n",
    "        display(HTML(f\"<h4>Generated ({style})</h4><pre style='white-space:pre-wrap'>{generated}</pre>\"))\n",
    "\n",
    "def save_output(_):\n",
    "    if hasattr(output_area, 'generated_result'):\n",
    "        with open(\"generated_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(output_area.generated_result)\n",
    "        with output_area:\n",
    "            display(HTML(\"<p><b>✅ Saved as 'generated_text.txt' in Colab session.</b></p>\"))\n",
    "    else:\n",
    "        with output_area:\n",
    "            display(HTML(\"<p style='color:red'><b>No generated text. Please generate first.</b></p>\"))\n",
    "\n",
    "def download_output(_):\n",
    "    if hasattr(output_area, 'generated_result'):\n",
    "        with open(\"generated_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(output_area.generated_result)\n",
    "        files.download(\"generated_text.txt\")\n",
    "    else:\n",
    "        with output_area:\n",
    "            display(HTML(\"<p style='color:red'><b>No generated text to download.</b></p>\"))\n",
    "\n",
    "insert_sample_btn.on_click(insert_sample)\n",
    "generate_btn.on_click(run_generation)\n",
    "save_btn.on_click(save_output)\n",
    "download_btn.on_click(download_output)\n",
    "\n",
    "controls_top = widgets.HBox([style_dd, generate_btn, save_btn, download_btn])\n",
    "controls_bottom = widgets.HBox([maxlen_slider, temp_slider, top_p_slider])\n",
    "\n",
    "display(HTML(\"<h2>✨ Text Generation with GPT-2</h2>\"))\n",
    "display(prompt_area)\n",
    "display(widgets.HBox([sample_dd, insert_sample_btn]))\n",
    "display(controls_top)\n",
    "display(controls_bottom)\n",
    "display(output_area)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
